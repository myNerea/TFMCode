import aiohttp
import json
from utils.utils_idiomas import detectar_idioma_llm

async def traducir_a_espanol_llm(texto, modelo="llama3.2"):
    """
    Genera la traducci√≥n al espa√±ol del texto recibido mediante el uso de un modelo Llama3.2.
    Recibe un texto, que ser√° la pregunta del usuario.
    Devuelve el texto traducido.

    """

    prompt = (
        "Por favor, traduce el siguiente texto al espa√±ol de forma precisa y natural. "
        "Solo devuelve la traducci√≥n, sin explicaciones, notas, ni ning√∫n texto adicional. "
        "No incluyas comillas ni etiquetas, solo el texto traducido.\n\n"
        f"{texto}"
    )

    data = {
        "model": modelo,
        "messages": [
            {
                "role": "system",
                "content": "Eres un traductor profesional. Solo proporcionas la traducci√≥n solicitada sin agregar nada m√°s."
            },
            {"role": "user", "content": prompt}
        ]
    }

    try:
        async with aiohttp.ClientSession() as session:
            async with session.post("http://localhost:11434/api/chat", json=data) as response:
                response.raise_for_status()

                traduccion = ""
                async for line in response.content:
                    line = line.decode("utf-8").strip()
                    if line:
                        try:
                            json_data = json.loads(line)
                            contenido = json_data.get("message", {}).get("content", "")
                            traduccion += contenido
                        except json.JSONDecodeError:
                            pass
                # Devuelve la traducci√≥n eliminando espacios que se hayan podido generar delante o detr√°s de la frase.
                return traduccion.strip()

    except Exception as e:
        print(f"‚ùå Error en traducci√≥n LLM: {e}")
        return texto


async def preparar_pregunta(texto, modelo="llama3.2"):
    """
    Detecta idioma y si hay mezcla. Si no est√° en espa√±ol, traduce.
    Devuelve: texto_espa√±ol, idioma_detectado, mezcla_idiomas
    """
    # Usamos la funcion en utils_idomas.py para determinar el idioma principal y si hab√≠a mezcla.
    # Info contedr√° un diccionario.
    info = await detectar_idioma_llm(texto, modelo=modelo)
    # Extraemos la clave del diccionario para obtener el idioma principal detectado.
    idioma = info.get("idioma_detectado", "espa√±ol")
    # Extraemos la clave del diccionario para obtener si hab√≠a o no mezcla de idiomas.
    mezcla = info.get("mezcla_idiomas", False)

    # Si el idioma es distinto de espa√±ol, llamamos a la funci√≥n anterior para generar la traducci√≥n mediante
    # un LLM.
    if idioma != "espa√±ol":
        traduccion = await traducir_a_espanol_llm(texto, modelo=modelo)
        # Mostramos la traducci√≥n que devuelve el modelo.
        print(f"üìù Traducci√≥n pregunta: {traduccion}")
        # Mostramos el idioma original en el que estaba la pregunta.
        print(f"‚úÖ La pregunta se detect√≥ en idioma: {idioma}. Se tradujo a espa√±ol si era distinto.")
        # Devolvemos la traduccion, el idioma principal y si el texto ten√≠a o no mezcla de idiomas.
        return traduccion, idioma, mezcla
    else:
        # En caso de estar en espa√±ol, devolvemos el texto original que se introdujo, el idioma principal y
        # si ten√≠a mezcla o no.
        # T√©ngase en cuenta, que si entra aqu√≠, el idioma es espa√±ol y mezcla es False.
        print("‚úÖ La pregunta ya est√° en espa√±ol, no se tradujo")
        return texto, idioma, mezcla
